{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmetics Generative Formulation\n",
    "## Phyisiochemical properties prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/data/RTV/DEMOR424/BIOVIA/BPP2022/public/cpgretail/Cosmetics Generative Formulation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "tags": [
     "ppDataConnector"
    ]
   },
   "outputs": [],
   "source": [
    "# WARNING: DO NOT REMOVE OR MODIFY.\n",
    "runningInJupyter = True\n",
    "\n",
    "from plp_jupyter_data_loader import loadPipelinePilotData\n",
    "plp_df, plp_params, plp_globals = loadPipelinePilotData()\n",
    "import pandas as pd\n",
    "if plp_df.shape[0] > 0:\n",
    "    print(\"plp_df.dtypes:\\n\" + plp_df.dtypes.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "#     'Play Time (s)',\n",
    "#     'Stickiness',\n",
    "#     'Slippery Finish',\n",
    "#     'Spreadability',\n",
    "#     'Viscosity (Pa.s)',\n",
    "#     'pH',\n",
    "#     'Color',\n",
    "#     'Odor',\n",
    "    'homogeneity'\n",
    "]\n",
    "\n",
    "to_drop = [\n",
    "    'formula_id',\n",
    "    'homogeneity_proba',\n",
    "    'Stability'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = plp_df.drop(columns=targets+to_drop).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieve targets train models\n",
    "Using grid search for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_metrics = {}\n",
    "for tgt in targets:\n",
    "    y = plp_df[tgt].astype(int).values\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=2025\n",
    "    )\n",
    "\n",
    "    # Initialize the Gradient Boosting model\n",
    "    if tgt == 'homogeneity': \n",
    "        model = GradientBoostingClassifier(random_state=2025)\n",
    "    else: \n",
    "        model = GradientBoostingRegressor(random_state=2025)\n",
    "\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "#         'n_estimators': [100, 200, 500, 1000],\n",
    "#         'learning_rate': [0.01, 0.1, 0.2],\n",
    "#         'max_depth': [3, 5, 7, 9],\n",
    "        'n_estimators': [1000],\n",
    "        'learning_rate': [0.1],\n",
    "        'max_depth': [5],\n",
    "#       'min_samples_split': [2, 5, 10],\n",
    "#       'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Set up GridSearchCV\n",
    "    if tgt == 'homogeneity':\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=5, \n",
    "            scoring='neg_mean_squared_error',\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    print(\"Starting grid search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Save the best parameters and the corresponding score\n",
    "    with open('./Models/Metrics/{}_best_params.json'.format(tgt), 'w') as f:\n",
    "        # write the dictionary to the file in JSON format\n",
    "        json.dump(grid_search.best_params_, f)\n",
    "    \n",
    "    \n",
    "    # Evaluate the best model on the test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "\n",
    "    if tgt == 'homogeneity':\n",
    "        dic_metrics[tgt] = {\n",
    "            \"Precision\": precision_score(y_test, y_pred),\n",
    "            \"Recall\": recall_score(y_test, y_pred),\n",
    "            \"F1\": f1_score(y_test, y_pred),\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred)\n",
    "        } \n",
    "    else:\n",
    "        dic_metrics[tgt] = {\n",
    "            \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "            \"R2\": r2_score(y_test, y_pred)\n",
    "        }       \n",
    "        \n",
    "\n",
    "    # Save metrics file\n",
    "    with open('./Models/Metrics/{}_metrics.json'.format(tgt), 'w') as f:\n",
    "        # write the dictionary to the file in JSON format\n",
    "        json.dump(dic_metrics, f)\n",
    "        \n",
    "        \n",
    "    # Save the model to disk\n",
    "    filename = './Models/model_gradient_boosting_{}.sav'.format(tgt)\n",
    "    pickle.dump(best_model, open(filename, 'wb'))\n",
    "    print('Model saved to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plp_df = pd.DataFrame(dic_metrics)  # Return metrics dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
