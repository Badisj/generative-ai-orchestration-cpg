{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dairy Generative Formulation\n",
    "### Model training and deployment using SageMaker Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "# ========================== low-level service client of the boto3 session ==========================\n",
    "config = botocore.config.Config(user_agent_extra='bedissj-1699438736259')\n",
    "\n",
    "bucket =  \"dairy-generative-formulation\"\n",
    "\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime',\n",
    "                          config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm,\n",
    "                         sagemaker_runtime_client=sm_runtime,\n",
    "                         default_bucket = bucket)\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "from sagemaker.estimator import Model\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput, CreateModelInput\n",
    "\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.workflow.steps import TuningStep, ProcessingStep, CreateModelStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo, ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.pipeline import Pipeline \n",
    "\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_s3_uri = \"s3://{}/data/raw/\".format(bucket)\n",
    "print(raw_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat, ParameterInteger\n",
    "\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name='input-data',\n",
    "    default_value='/opt/ml/processing/input/data'\n",
    ")\n",
    "\n",
    "output_data = ParameterString(\n",
    "    name='output-data',\n",
    "    default_value='/opt/ml/processing/output'\n",
    ")\n",
    "\n",
    "validation_split_percentage = ParameterFloat(\n",
    "    name='validation-split-percentage',\n",
    "    default_value=0.1\n",
    ")\n",
    "\n",
    "\n",
    "test_split_percentage = ParameterFloat(\n",
    "    name='test-split-percentage',\n",
    "    default_value=0.2\n",
    ")\n",
    "\n",
    "feature_group_name = ParameterString(\n",
    "    name='feature-group-name',\n",
    "    default_value='dairy-generative-formulation-feature-group'\n",
    ")\n",
    "\n",
    "\n",
    "feature_store_offline_prefix = ParameterString(\n",
    "    name='feature-store-offline-prefix',\n",
    "    default_value=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "\n",
    "# ========================== Processing Inputs ==========================\n",
    "processing_inputs = [\n",
    "    ProcessingInput(\n",
    "        input_name='dairy-generative-formulation-raw-data',\n",
    "        source=raw_data_s3_uri,\n",
    "        destination=input_data.default_value,\n",
    "        s3_data_distribution_type='ShardedByS3Key'\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# ========================== Processing Outputs ==========================\n",
    "output_data_train = output_data.default_value + '/train'\n",
    "output_data_validation = output_data.default_value + '/validation'\n",
    "output_data_test = output_data.default_value + '/test'\n",
    "output_encoder = output_data.default_value + '/encoder'\n",
    "\n",
    "\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(source=output_data_train,\n",
    "                    output_name='dairy-generative-formulation-train',\n",
    "                     s3_upload_mode='EndOfJob'),\n",
    "    \n",
    "    ProcessingOutput(source=output_data_validation,\n",
    "                    output_name='dairy-generative-formulation-validation',\n",
    "                    s3_upload_mode='EndOfJob'),\n",
    "    \n",
    "    ProcessingOutput(source=output_data_test,\n",
    "                    output_name='dairy-generative-formulation-test',\n",
    "                    s3_upload_mode='EndOfJob'),\n",
    "    \n",
    "    ProcessingOutput(source=output_encoder,\n",
    "                    output_name='dairy-generative-formulation-encoder',\n",
    "                    s3_upload_mode='EndOfJob')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== Processing Parameters ==========================\n",
    "FRAMEWORK_VERSION = '1.0-1'\n",
    "processing_instance_type = 'ml.t3.medium'\n",
    "processing_instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearnProcessor\n",
    "\n",
    "# ========================== Instanciate SKLearn Processor ==========================\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    sagemaker_session=sess,\n",
    "    env={\n",
    "        'AWS_DEFAULT_REGION': region\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='DataProcessing',\n",
    "    code='./src/processing.py',\n",
    "    processor=sklearn_processor,\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    job_arguments=[\n",
    "        '--input-data', str(input_data.default_value),\n",
    "        '--output-data', str(output_data.default_value),\n",
    "        '--validation-split-percentage', str(validation_split_percentage.default_value),\n",
    "        '--test-split-percentage', str(test_split_percentage.default_value),\n",
    "        '--feature-store-offline-prefix', str(feature_store_offline_prefix.default_value),\n",
    "        '--feature-group-name', str(feature_group_name.default_value)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn_processor.run(\n",
    "#     code='./src/processing.py',\n",
    "#     inputs=processing_inputs,\n",
    "#     outputs=processing_outputs,\n",
    "#     arguments=[\n",
    "#         '--input-data', str(input_data.default_value),\n",
    "#         '--output-data', str(output_data.default_value),\n",
    "#         '--validation-split-percentage', str(validation_split_percentage.default_value),\n",
    "#         '--test-split-percentage', str(test_split_percentage.default_value),\n",
    "#         '--feature-store-offline-prefix', str(feature_store_offline_prefix.default_value),\n",
    "#         '--feature-group-name', str(feature_group_name.default_value)\n",
    "#     ],\n",
    "#     wait=True,\n",
    "#     logs=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# pprint(sklearn_processor.latest_job.describe()['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hyperparameter tuning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= Training resources =========================\n",
    "training_instance_type = 'ml.m5.large'\n",
    "training_instance_count = 1\n",
    "\n",
    "\n",
    "# ========================== training inputs ==========================\n",
    "objective = 'validation:rmse'\n",
    "metric_definitions = [\n",
    "    {'Name': 'validation:rmse', 'Regex': 'val_rmse: ([0-9.]+)'},\n",
    "    {'Name': 'validation:mse', 'Regex': 'val_mse: ([0-9.]+)'},\n",
    "    {'Name': 'validation:mae', 'Regex': 'val_mae: ([0-9.]+)'},\n",
    "    {'Name': 'validation:r2', 'Regex': 'val_r2: ([0-9.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================  Sensory attributes to loop on  =========================\n",
    "\n",
    "models_s3_uri = \"s3://{}/models\".format(bucket)\n",
    "\n",
    "sensory_attributes = [\n",
    "    'Flavor_intensity ',\n",
    "    'sweetness',\n",
    "    'Fruit_intensity',\n",
    "    'Chalkiness',\n",
    "    'Color_intensity',\n",
    "    'thickness',\n",
    "    'Coating',\n",
    "    'Global Appreciation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================  Hyperparameter tuning job parameters  =========================\n",
    "max_jobs = 2\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in sensory_attributes:\n",
    "    # ===========================================================================================\n",
    "    # =========================  Static hyperparameters =========================\n",
    "    static_hyperparameters = {\n",
    "        'random_state': 2024,\n",
    "        'sensory_output': attribute\n",
    "    }\n",
    "\n",
    "\n",
    "    # ==========================  Hyperparameter ranges ==========================\n",
    "\n",
    "    hyperparameter_ranges = {\n",
    "        'n_estimators': IntegerParameter(min_value=10, \n",
    "                                         max_value=200, \n",
    "                                         scaling_type='Logarithmic'),\n",
    "        \n",
    "        'max_depth': IntegerParameter(min_value=3, \n",
    "                                      max_value=10, \n",
    "                                      scaling_type='Linear'),\n",
    "        \n",
    "        'criterion': CategoricalParameter(values=['squared_error', 'friedman_mse'])\n",
    "    }\n",
    "\n",
    "\n",
    "    # =========================  Instanciate estimator  =========================\n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point='./src/training.py',\n",
    "        framework_version=FRAMEWORK_VERSION,\n",
    "        instance_type=training_instance_type,\n",
    "        instance_count=training_instance_count,\n",
    "        role=role,\n",
    "        hyperparameters=static_hyperparameters,\n",
    "        output_path=os.path.join(models_s3_uri, attribute),\n",
    "        metric_definitions=metric_definitions\n",
    "    )\n",
    "\n",
    "\n",
    "    # =========================  Instanciate hyperparameter tuner  =========================\n",
    "    tuner = HyperparameterTuner(\n",
    "            estimator=sklearn_estimator,\n",
    "            hyperparameter_ranges=hyperparameter_ranges,\n",
    "            objective_metric_name=objective,\n",
    "            metric_definitions=metric_definitions,\n",
    "            strategy='Bayesian',\n",
    "            objective_type='Minimize',\n",
    "            max_jobs=max_jobs,\n",
    "            max_parallel_jobs=max_parallel_jobs,\n",
    "            autotune=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # ====================== Configure training/tuning inputs ======================\n",
    "    tuning_inputs = {\n",
    "        'train': TrainingInput(\n",
    "            # s3_data='s3://dairy-generative-formulation/sagemaker-scikit-learn-2024-12-02-14-43-07-811/output/dairy-generative-formulation-train',\n",
    "            #s3_data=sklearn_processor.latest_job.describe()['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'],\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'dairy-generative-formulation-train'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv',\n",
    "            input_mode='File'\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            # s3_data='s3://dairy-generative-formulation/sagemaker-scikit-learn-2024-12-02-14-43-07-811/output/dairy-generative-formulation-validation',\n",
    "            # s3_data=sklearn_processor.latest_job.describe()['ProcessingOutputConfig']['Outputs'][1]['S3Output']['S3Uri'],\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'dairy-generative-formulation-validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv',\n",
    "            input_mode='File'\n",
    "        )\n",
    "    }\n",
    "\n",
    " \n",
    "    # ====================== Cache configuration  ======================\n",
    "    cache_config = CacheConfig(enable_caching=True, expire_after=\"PT1H\") # PT1H represents `one hour`\n",
    "\n",
    "\n",
    "    # ====================== Configure hyperparameter tuning step ======================\n",
    "    tuning_step =TuningStep(\n",
    "        name='ModelTraining',\n",
    "        tuner=tuner,\n",
    "        inputs=tuning_inputs,\n",
    "        cache_config=cache_config\n",
    "    )\n",
    "\n",
    "    \n",
    "    # =========================================================================================\n",
    "    # ============================ Configure processing job unputs ============================\n",
    "    evaluation_metrics = PropertyFile(\n",
    "        name='EvaluationReport',\n",
    "        output_name='metrics',\n",
    "        # path='evaluation_{}.json'.format(attribute)\n",
    "        path=os.path.join(models_s3_uri, 'evaluation', attribute, 'evaluation_{}.json'.format(attribute))\n",
    "    )\n",
    "\n",
    "    sensory_output_arg = ParameterString(\n",
    "        name='sensory-target',\n",
    "        default_value=attribute\n",
    "    )\n",
    "    \n",
    "\n",
    "    # ============================ Instanciate evaluation processor ===========================\n",
    "    evaluation_processor = SKLearnProcessor(\n",
    "        framework_version=FRAMEWORK_VERSION,\n",
    "        role=role,\n",
    "        instance_type=processing_instance_type,\n",
    "        instance_count = processing_instance_count,\n",
    "        sagemaker_session=sess,\n",
    "        env={'AWS_DEFAULT_REGION': region}  \n",
    "    )\n",
    "    \n",
    "    # ====================  Configure processing job for model evaluation  ====================\n",
    "    evaluation_step = ProcessingStep(\n",
    "        name='EvaluateMetrics',\n",
    "        code='./src/evaluate_metrics.py',\n",
    "        processor=evaluation_processor,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=tuning_step.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "                # source=tuning_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination='/opt/ml/processing/input/model'\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    'dairy-generative-formulation-test'\n",
    "                ].S3Output.S3Uri,\n",
    "                destination='/opt/ml/processing/input/data'\n",
    "            )\n",
    "        ],\n",
    "        outputs = [\n",
    "            ProcessingOutput(\n",
    "                output_name='metrics',\n",
    "                s3_upload_mode='EndOfJob',\n",
    "                source='/opt/ml/processing/output/metrics/',\n",
    "                destination=os.path.join(models_s3_uri, 'evaluation', attribute)\n",
    "            )\n",
    "        ],\n",
    "        property_files=[evaluation_metrics],\n",
    "        job_arguments=['--sensory-target', str(sensory_output_arg.default_value)]\n",
    "    )\n",
    "\n",
    "\n",
    "    # =========================================================================================\n",
    "    # ======================== Configure model registration parameters ========================\n",
    "    deploy_instance_type = ParameterString(\n",
    "        name='deploy_instance_type',\n",
    "        default_value='ml.m5.large'\n",
    "    )\n",
    "\n",
    "    deploy_instance_count = ParameterInteger(\n",
    "        name=\"DeployInstanceCount\",\n",
    "        default_value=1\n",
    "    )\n",
    "\n",
    "    model_package_group_name = ParameterString(\n",
    "        name='model_package_group_name',\n",
    "        default_value='dairy-gen-form-{}-model-package-group'.format(attribute).replace(' ', '').replace('_', '-')\n",
    "    )\n",
    "\n",
    "    model_approval_status = ParameterString(\n",
    "        name='model_approval_status',\n",
    "        default_value='PendingManualApproval'\n",
    "    )\n",
    "    \n",
    "    # ================== Configure model metrics source from evaluation step ==================\n",
    "    model_metrics = ModelMetrics(\n",
    "        model_statistics=MetricsSource(\n",
    "            content_type=['application/json'],\n",
    "            s3_uri=evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'] + '/evaluation_{}.json'.format(attribute)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    # =========================== Retrieve image uri for inference ============================\n",
    "    inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "        framework='sklearn',\n",
    "        version=FRAMEWORK_VERSION,\n",
    "        instance_type=deploy_instance_type,\n",
    "        image_scope='inference',\n",
    "        region=region,\n",
    "    )\n",
    "    \n",
    "\n",
    "    # =========================================================================================\n",
    "    # ======================== Create model for model deployment step =========================\n",
    "    timestamp = int(time.time())\n",
    "    model_name = f'{attribute}-{timestamp}'.replace(' ', '').replace('_', '-')\n",
    "\n",
    "    model = Model(\n",
    "        name=model_name,\n",
    "        entry_point='./src/inference.py',\n",
    "        image_uri=inference_image_uri,\n",
    "        model_data=tuning_step.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "        sagemaker_session=sess,\n",
    "        role=role\n",
    "    )\n",
    "\n",
    "    model_inputs = CreateModelInput(\n",
    "        instance_type=deploy_instance_type\n",
    "    )\n",
    "\n",
    "    # ================================= Create Model Step ==================================\n",
    "    create_model_step = CreateModelStep(\n",
    "        name='CreateModel',\n",
    "        model=model,\n",
    "        inputs=model_inputs\n",
    "    )\n",
    "\n",
    "    # ========================== Configure model registration step ============================\n",
    "    # register_args = model.register(\n",
    "    #     content_types=[\"text/csv\"],\n",
    "    #     response_types=[\"text/csv\"],\n",
    "    #     inference_instances=[deploy_instance_type.default_value],\n",
    "    #     transform_instances=[deploy_instance_type.default_value],\n",
    "    #     model_package_group_name=model_package_group_name.default_value,\n",
    "    #     approval_status=model_approval_status.default_value,\n",
    "    # )\n",
    "    \n",
    "    # register_best_step = ModelStep(name=\"RegisterBestAbaloneModel\", step_args=register_args)\n",
    "\n",
    "    \n",
    "    register_step = RegisterModel(\n",
    "        name='RegisterModel',\n",
    "        estimator=sklearn_estimator,\n",
    "        image_uri=inference_image_uri,\n",
    "        inference_instances=[deploy_instance_type],\n",
    "        transform_instances=[deploy_instance_type],\n",
    "        model_data=tuning_step.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "        # model_package_group_name=model_package_group_name,\n",
    "        # model_metrics=model_metrics,\n",
    "        # approval_status=model_approval_status,\n",
    "        content_types=['text/csv'],\n",
    "        response_types=['text/csv'],\n",
    "    )\n",
    "\n",
    "    # =========================================================================================\n",
    "    # ================================ Cofigure Condition Step ================================\n",
    "    minimum_r2_value = ParameterFloat(\n",
    "        name='MinimumR2',\n",
    "        default_value=0.80\n",
    "    )\n",
    "\n",
    "    maximum_rmse_value = ParameterFloat(\n",
    "        name='MaximumRMSE',\n",
    "        default_value=0.20\n",
    "    )\n",
    "\n",
    "\n",
    "    minimum_r2_condition = ConditionGreaterThanOrEqualTo(\n",
    "        left=JsonGet(\n",
    "            step_name=evaluation_step.name,\n",
    "            step=evaluation_step,\n",
    "            property_file=evaluation_metrics,\n",
    "            json_path=\"metrics.R2.value\"\n",
    "        ),\n",
    "        \n",
    "        right=0.80\n",
    "    )\n",
    "\n",
    "    maximum_rmse_condition = ConditionLessThanOrEqualTo(\n",
    "        left=JsonGet(\n",
    "            step_name=evaluation_step.name,\n",
    "            step=evaluation_step,\n",
    "            property_file=evaluation_metrics,\n",
    "            json_path=\"metrics.RMSE.value\"\n",
    "        ),\n",
    "        \n",
    "        right=0.20\n",
    "    )\n",
    "\n",
    "\n",
    "    condition_step = ConditionStep(\n",
    "        name='ModelValidationConditions',\n",
    "        conditions=[minimum_r2_condition,],\n",
    "        if_steps = [create_model_step, register_step],\n",
    "        else_steps = []\n",
    "    )\n",
    "\n",
    "\n",
    "    # =========================================================================================\n",
    "    # =============================== Create & Execute Pipeline ===============================\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_name = f'dairy-gen-form-{attribute}-pipeline-{timestamp}'.replace(' ', '').replace('_', '-')\n",
    "\n",
    "    pipeline_parameters = [\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        training_instance_count,\n",
    "        model_package_group_name,\n",
    "        model_approval_status,\n",
    "        deploy_instance_type,\n",
    "        minimum_r2_value,\n",
    "        maximum_rmse_value\n",
    "    ]\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        sagemaker_session=sess,\n",
    "        parameters=pipeline_parameters,\n",
    "        steps=[ \n",
    "            # processing_step,\n",
    "            # tuning_step, \n",
    "            # evaluation_step,\n",
    "            condition_step\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = pipeline.create(role_arn=role)\n",
    "    execution = pipeline.start()\n",
    "\n",
    "    # =============================== Pipeline description ===============================\n",
    "    print('Executing training pipeline for sensory property: ', attribute)\n",
    "    \n",
    "    # Pipeline execution overview\n",
    "    pipeline_execution = sm.list_pipeline_executions(PipelineName=pipeline_name)['PipelineExecutionSummaries']\n",
    "    pipeline_execution_status = pipeline_execution[0][\"PipelineExecutionStatus\"]\n",
    "\n",
    "    while pipeline_execution_status == \"Executing\":\n",
    "        pipeline_execution = sm.list_pipeline_executions(PipelineName=pipeline_name)['PipelineExecutionSummaries']\n",
    "        pipeline_execution_status = pipeline_execution[0][\"PipelineExecutionStatus\"]\n",
    "\n",
    "    pprint(pipeline_execution)\n",
    "\n",
    "\n",
    "    # Retrieve tuning job artifacts\n",
    "    training_job_arn=None\n",
    "\n",
    "    for execution_step in execution_steps:\n",
    "        if execution_step[\"StepName\"] == \"ModelTrainingl\": \n",
    "            training_job_arn = execution_step['Metadata']['TuningJob']['Arn']      \n",
    "            pprint(execution_step)\n",
    "            break\n",
    "    print('Tuning job ARN: {}'.format(training_job_arn))\n",
    "            \n",
    "    training_job_name = training_job_arn.split('/')[-1]\n",
    "    print('Tuning job Name: {}'.format(training_job_name))\n",
    "\n",
    "\n",
    "    # Focus on model performance\n",
    "    processing_job_name = None\n",
    "\n",
    "    for execution_step in reversed(execution_steps):\n",
    "        if execution_step[\"StepName\"] == \"EvaluateMetrics\": \n",
    "            processing_job_name=execution_step['Metadata']['ProcessingJob']['Arn'].split('/')[-1]\n",
    "\n",
    "    describe_evaluation_processing_job_response = sm.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "\n",
    "    evaluation_metrics_s3_uri = describe_evaluation_processing_job_response['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "    print('Evaluation output: {}'.format(evaluation_metrics_s3_uri))\n",
    "\n",
    "    evaluation_json = sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n",
    "        evaluation_metrics_s3_uri\n",
    "    ))\n",
    "\n",
    "    pprint(json.loads(evaluation_json))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.list_executions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in pipeline_parameters:\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline execution overview\n",
    "pipeline_execution = sm.list_pipeline_executions(PipelineName=pipeline_name)['PipelineExecutionSummaries']\n",
    "pipeline_execution_status = pipeline_execution[0][\"PipelineExecutionStatus\"]\n",
    "\n",
    "while pipeline_execution_status == \"Executing\":\n",
    "    pipeline_execution = sm.list_pipeline_executions(PipelineName=pipeline_name)['PipelineExecutionSummaries']\n",
    "    pipeline_execution_status = pipeline_execution[0][\"PipelineExecutionStatus\"]\n",
    "\n",
    "pprint(pipeline_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_instance_type = ParameterString(\n",
    "    name='deploy_instance_type',\n",
    "    default_value='ml.m5.large'\n",
    ")\n",
    "\n",
    "deploy_instance_count = ParameterInteger(\n",
    "    name=\"DeployInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "model_package_group_name = ParameterString(\n",
    "    name='model_package_group_name',\n",
    "    default_value='dairy-generative-formulation-{}-model-package-group'.format(attribute)\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name='model_approval_status',\n",
    "    default_value='PendingManualApproval'\n",
    ")\n",
    "\n",
    "# ================== Configure model metrics source from evaluation step ==================\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        content_type=['application/json'],\n",
    "        s3_uri=evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'] + '/evaluation_{}.json'.format(attribute)\n",
    "    )\n",
    ")\n",
    "\n",
    "# =========================== Retrieve image uri for inference ============================\n",
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='sklearn',\n",
    "    version=FRAMEWORK_VERSION,\n",
    "    instance_type=deploy_instance_type,\n",
    "    image_scope='inference',\n",
    "    region=region,\n",
    ")\n",
    "\n",
    "# ========================== Configure model registration step ============================\n",
    "register_step = RegisterModel(\n",
    "    name='RegisterModel',\n",
    "    estimator=tuner.best_estimator,\n",
    "    image_uri=inference_image_uri,\n",
    "    inference_instances=[deploy_instance_type],\n",
    "    transform_instances=[deploy_instance_type],\n",
    "    model_data=tuning_step.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "    # model_data=tuning_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    "    approval_status=model_approval_status,\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegisterModel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
