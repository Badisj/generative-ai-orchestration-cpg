{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae6281d",
   "metadata": {},
   "source": [
    "# Train and Evaluate Models for Chocolate Targets\n",
    "\n",
    "This notebook demonstrates how to load formulation data, ensure target columns are present (by running the estimator if necessary), train Random Forest and Gradient Boosting models for each target, evaluate, save models and metrics, and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fb2578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T22:21:41.655465Z",
     "iopub.status.busy": "2025-12-02T22:21:41.655050Z",
     "iopub.status.idle": "2025-12-02T22:21:44.010634Z",
     "shell.execute_reply": "2025-12-02T22:21:44.009817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set. INPUT: data\\Chocolate_bar_dataset_with_features.csv PROCESS_SRC: src\\process\\2. Chocolate_target_estimation.py\n"
     ]
    }
   ],
   "source": [
    "# Setup imports and paths\n",
    "from pathlib import Path\n",
    "import sys, os, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "ROOT = Path('.')\n",
    "DATA_DIR = ROOT / 'data'\n",
    "PROCESS_SRC = ROOT / 'src' / 'process' / '2. Chocolate_target_estimation.py'\n",
    "INPUT_CSV = DATA_DIR / 'Chocolate_bar_dataset_with_features.csv'\n",
    "OUTPUTS = ROOT / 'outputs'\n",
    "MODELS_DIR = OUTPUTS / 'models'\n",
    "OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Paths set. INPUT:', INPUT_CSV, 'PROCESS_SRC:', PROCESS_SRC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d52a82",
   "metadata": {},
   "source": [
    "## Extract `target_columns` from the process script\n",
    "We parse the Python source file to find the literal `target_columns` list used by the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5135dcc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T22:21:44.013775Z",
     "iopub.status.busy": "2025-12-02T22:21:44.013392Z",
     "iopub.status.idle": "2025-12-02T22:21:44.023973Z",
     "shell.execute_reply": "2025-12-02T22:21:44.022900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 target columns\n",
      "['hardness_newtons', 'snap_force_newtons', 'viscosity_pas', 'particle_size_d50_micron', 'color_l_value', 'color_a_value', 'color_b_value', 'gloss_units', 'sweetness_score', 'bitterness_score', 'creaminess_score', 'overall_flavor_balance', 'texture_liking', 'overall_preference', 'fat_bloom_severity', 'sugar_bloom_severity', 'color_delta_e', 'hardness_change_pct', 'peroxide_value', 'free_fatty_acids', 'water_activity', 'moisture_content_pct', 'overall_acceptability', 'shelf_life_exceeded']\n"
     ]
    }
   ],
   "source": [
    "def extract_target_columns(source_path: Path):\n",
    "    src = source_path.read_text(encoding='utf-8')\n",
    "    tree = ast.parse(src)\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign):\n",
    "            for t in node.targets:\n",
    "                if isinstance(t, ast.Name) and t.id == 'target_columns':\n",
    "                    return ast.literal_eval(node.value)\n",
    "    raise RuntimeError('target_columns not found in process source')\n",
    "\n",
    "target_columns = extract_target_columns(PROCESS_SRC)\n",
    "print('Found', len(target_columns), 'target columns')\n",
    "print(target_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543add3",
   "metadata": {},
   "source": [
    "## Load dataset and synthesize targets if missing\n",
    "If the input CSV doesn't already include the target columns, we will import `estimate_chocolate_targets` from the process script and run it to create target columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea863c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T22:21:44.027194Z",
     "iopub.status.busy": "2025-12-02T22:21:44.026642Z",
     "iopub.status.idle": "2025-12-02T22:21:44.099134Z",
     "shell.execute_reply": "2025-12-02T22:21:44.097569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (107, 91)\n",
      "Missing targets: ['particle_size_d50_micron']\n",
      "Running estimator to generate targets...\n",
      "Estimating target values based on scientific correlations...\n",
      "1. Estimating physical properties...\n",
      "2. Estimating color properties...\n",
      "3. Estimating sensory properties...\n",
      "4. Estimating stability properties...\n",
      "5. Rounding values for measurement realism...\n",
      "6. Generating summary statistics...\n",
      "\n",
      "Target Value Ranges (Estimated):\n",
      "--------------------------------------------------\n",
      "hardness_newtons          |  31.60 -  48.00 | Mean:  45.12\n",
      "snap_force_newtons        |  23.80 -  28.00 | Mean:  27.80\n",
      "viscosity_pas             |   1.50 -   8.66 | Mean:   6.08\n",
      "particle_size_d50_micron  |  12.60 -  20.40 | Mean:  16.27\n",
      "color_l_value             |  25.80 -  53.40 | Mean:  42.36\n",
      "color_a_value             |   9.20 -  14.20 | Mean:  11.70\n",
      "color_b_value             |  15.70 -  29.90 | Mean:  22.87\n",
      "gloss_units               |  93.20 -  95.00 | Mean:  94.98\n",
      "sweetness_score           |   1.00 -   7.30 | Mean:   4.21\n",
      "bitterness_score          |   2.90 -  10.00 | Mean:   6.40\n",
      "creaminess_score          |   5.00 -  10.00 | Mean:   8.76\n",
      "overall_flavor_balance    |   3.40 -   7.30 | Mean:   5.91\n",
      "texture_liking            |   5.80 -  10.00 | Mean:   7.75\n",
      "overall_preference        |   3.00 -   6.30 | Mean:   4.50\n",
      "fat_bloom_severity        |   3.00 -   5.00 | Mean:   4.25\n",
      "sugar_bloom_severity      |   0.00 -   5.00 | Mean:   2.02\n",
      "color_delta_e             |   2.40 -  15.00 | Mean:   4.40\n",
      "hardness_change_pct       |   2.00 -  25.00 | Mean:  15.95\n",
      "peroxide_value            |   1.59 -   6.13 | Mean:   3.58\n",
      "free_fatty_acids          |   1.05 -   4.00 | Mean:   3.18\n",
      "water_activity            |   0.43 -   0.71 | Mean:   0.58\n",
      "moisture_content_pct      |   1.19 -   3.05 | Mean:   1.90\n",
      "overall_acceptability     |   2.00 -   5.70 | Mean:   3.76\n",
      "shelf_life_exceeded       |   1.00 -   1.00 | Mean:   1.00\n",
      "\n",
      "Total formulations processed: 107\n",
      "Target columns estimated: 24\n",
      "Shelf life failures: 107/107 formulations\n",
      "\n",
      "Correlation Validation Examples:\n",
      "total_cocoa_pct vs hardness_newtons: r = 0.538\n",
      "sweetness_ratio vs sweetness_score: r = 0.914\n",
      "oxidation_risk_index vs peroxide_value: r = 0.238\n",
      "Saved enhanced CSV to outputs\\complete_formulations_with_targets.csv\n"
     ]
    }
   ],
   "source": [
    "if not INPUT_CSV.exists():\n",
    "    raise FileNotFoundError(f'Input CSV not found: {INPUT_CSV}')\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print('Loaded data shape:', df.shape)\n",
    "missing = [t for t in target_columns if t not in df.columns]\n",
    "if missing:\n",
    "    print('Missing targets:', missing)\n",
    "    mod = SourceFileLoader('estimator', str(PROCESS_SRC)).load_module()\n",
    "    if not hasattr(mod, 'estimate_chocolate_targets'):\n",
    "        raise RuntimeError('estimate_chocolate_targets not found in process source')\n",
    "    print('Running estimator to generate targets...')\n",
    "    df = mod.estimate_chocolate_targets(df)\n",
    "    out_csv = OUTPUTS / 'complete_formulations_with_targets.csv'\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print('Saved enhanced CSV to', out_csv)\n",
    "else:\n",
    "    print('All targets present in input CSV.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1b4be",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "Show a quick preview and numeric columns used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fcee81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T22:21:44.104159Z",
     "iopub.status.busy": "2025-12-02T22:21:44.103697Z",
     "iopub.status.idle": "2025-12-02T22:21:44.111451Z",
     "shell.execute_reply": "2025-12-02T22:21:44.109920Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (1369680060.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint('\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "display(df.head())\n",
    "print('\n",
    "Dtypes:')\n",
    "print(df.dtypes.value_counts())\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('\n",
    "Numeric columns count:', len(numeric_cols))\n",
    "print('Sample numeric columns:', numeric_cols[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887754ce",
   "metadata": {},
   "source": [
    "## Prepare features and targets\n",
    "We use numeric columns and drop the target columns from the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e90f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_present = [t for t in target_columns if t in df.columns]\n",
    "if not targets_present:\n",
    "    raise RuntimeError('No targets available to train on')\n",
    "numeric = df.select_dtypes(include=[np.number]).copy()\n",
    "X = numeric.drop(columns=targets_present, errors='ignore')\n",
    "Y = df[targets_present].copy()\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a1eb5",
   "metadata": {},
   "source": [
    "## Training helper and loop\n",
    "Define a helper to train per-target models (RandomForest and GradientBoosting) and collect metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_target(X, y, target_name, models_dir, random_state=42, test_size=0.2, n_estimators=100):\n",
    "    is_class = target_name == 'shelf_life_exceeded' or y.dropna().drop_duplicates().isin([0,1]).all()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y if is_class else None)\n",
    "    results = {}\n",
    "    preds_store = {}\n",
    "    if is_class:\n",
    "        models = {\n",
    "            'random_forest': RandomForestClassifier(n_estimators=n_estimators, random_state=random_state),\n",
    "            'grad_boost': GradientBoostingClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "        }\n",
    "    else:\n",
    "        models = {\n",
    "            'random_forest': RandomForestRegressor(n_estimators=n_estimators, random_state=random_state),\n",
    "            'grad_boost': GradientBoostingRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "        }\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        metric = {}\n",
    "        if is_class:\n",
    "            metric['accuracy'] = float(accuracy_score(y_test, preds))\n",
    "            metric['f1'] = float(f1_score(y_test, preds, zero_division=0))\n",
    "            try:\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    probs = model.predict_proba(X_test)[:,1]\n",
    "                    metric['roc_auc'] = float(roc_auc_score(y_test, probs))\n",
    "                else:\n",
    "                    metric['roc_auc'] = None\n",
    "            except Exception:\n",
    "                metric['roc_auc'] = None\n",
    "        else:\n",
    "            metric['r2'] = float(r2_score(y_test, preds))\n",
    "            metric['mae'] = float(mean_absolute_error(y_test, preds))\n",
    "            metric['rmse'] = float(mean_squared_error(y_test, preds, squared=False))\n",
    "        model_path = Path(models_dir) / f'{target_name}__{name}.joblib'\n",
    "        joblib.dump(model, model_path)\n",
    "        results[name] = {'model_path': str(model_path), 'metrics': metric}\n",
    "        preds_store[name] = {'X_test_index': X_test.index.tolist(), 'y_test': y_test.tolist(), 'preds': [float(x) for x in preds]}\n",
    "    return results, preds_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd230dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "artifacts = {}\n",
    "for tgt in targets_present:\n",
    "    print('Training target:', tgt)\n",
    "    try:\n",
    "        res, preds = train_for_target(X, Y[tgt], tgt, MODELS_DIR, n_estimators=100)\n",
    "        metrics[tgt] = res\n",
    "        artifacts[tgt] = preds\n",
    "    except Exception as e:\n",
    "        warnings.warn(f'Failed for {tgt}: {e}')\n",
    "\n",
    "# Create a DataFrame summarizing metrics\n",
    "rows = []\n",
    "for tgt, model_info in metrics.items():\n",
    "    for mname, info in model_info.items():\n",
    "        row = {'target': tgt, 'model': mname}\n",
    "        row.update(info['metrics'])\n",
    "        row['model_path'] = info['model_path']\n",
    "        rows.append(row)\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0783c",
   "metadata": {},
   "source": [
    "## Visualize example targets\n",
    "Plot a regression true vs predicted and classification confusion matrix where applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression visualization\n",
    "reg = None\n",
    "for t in targets_present:\n",
    "    if t != 'shelf_life_exceeded':\n",
    "        reg = t\n",
    "        break\n",
    "if reg and reg in metrics:\n",
    "    mpath = metrics[reg]['random_forest']['model_path']\n",
    "    model = joblib.load(mpath)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, Y[reg], test_size=0.2, random_state=42)\n",
    "    preds = model.predict(X_te)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(x=y_te, y=preds, alpha=0.6)\n",
    "    plt.plot([y_te.min(), y_te.max()], [y_te.min(), y_te.max()], 'r--')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f'True vs Predicted — {reg} (RF)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No regression target available for plot')\n",
    "\n",
    "# Classification visualization\n",
    "if 'shelf_life_exceeded' in metrics:\n",
    "    mpath = metrics['shelf_life_exceeded']['random_forest']['model_path']\n",
    "    clf = joblib.load(mpath)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, Y['shelf_life_exceeded'], test_size=0.2, random_state=42, stratify=Y['shelf_life_exceeded'])\n",
    "    preds = clf.predict(X_te)\n",
    "    cm = confusion_matrix(y_te, preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix — shelf_life_exceeded (RF)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No shelf_life_exceeded results available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58317c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics and artifacts\n",
    "metrics_out = OUTPUTS / 'metrics_summary.json'\n",
    "metrics_out.write_text(json.dumps(metrics, indent=2))\n",
    "print('Wrote metrics to', metrics_out)\n",
    "print('Saved model files:')\n",
    "for p in sorted(MODELS_DIR.rglob('*.joblib')):\n",
    "    print('-', p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
